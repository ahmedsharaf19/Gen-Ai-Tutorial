{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad432796",
   "metadata": {},
   "source": [
    "## Building A Chatbot\n",
    "\n",
    "<div dir='rtl'>\n",
    "\n",
    "ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù€ NotebookØŒ Ø³Ù†ØªØ¹Ù„Ù… ÙƒÙŠÙÙŠØ© ØªØµÙ…ÙŠÙ… ÙˆØªÙ†ÙÙŠØ° **Ø´Ø§Øª Ø¨ÙˆØª Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ù†Ù…ÙˆØ°Ø¬ Ù„ØºØ© ÙƒØ¨ÙŠØ± (LLM)**.  \n",
    "Ù‡Ø°Ø§ Ø§Ù„Ø´Ø§Øª Ø¨ÙˆØª Ø³ÙŠÙƒÙˆÙ† Ù‚Ø§Ø¯Ø±Ù‹Ø§ Ø¹Ù„Ù‰ Ø¥Ø¬Ø±Ø§Ø¡ Ù…Ø­Ø§Ø¯Ø«Ø© ÙˆØªØ°ÙƒØ± Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©.\n",
    "\n",
    "---\n",
    "\n",
    "### Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ù‡Ù…Ø©:\n",
    "\n",
    "Ø§Ù„Ø´Ø§Øª Ø¨ÙˆØª Ø§Ù„Ø°ÙŠ Ø³Ù†Ø¨Ù†ÙŠÙ‡ Ù‡Ù†Ø§ Ø³ÙŠØ³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºØ© Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©.  \n",
    "ÙˆÙ„ÙƒÙ† Ù‡Ù†Ø§Ùƒ Ø¹Ø¯Ø© Ù…ÙØ§Ù‡ÙŠÙ… Ù…ØªØ¹Ù„Ù‚Ø© Ù‚Ø¯ ØªÙˆØ¯ Ø§Ù„Ø§Ø·Ù„Ø§Ø¹ Ø¹Ù„ÙŠÙ‡Ø§ Ø£ÙŠØ¶Ù‹Ø§:\n",
    "\n",
    "- **Conversational RAG**: ØªÙ…ÙƒÙŠÙ† ØªØ¬Ø±Ø¨Ø© Ø´Ø§Øª Ø¨ÙˆØª ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù…ØµØ¯Ø± Ø®Ø§Ø±Ø¬ÙŠ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª.\n",
    "- **Agents**: Ø¨Ù†Ø§Ø¡ Ø´Ø§Øª Ø¨ÙˆØª ÙŠÙ…ÙƒÙ†Ù‡ Ø§ØªØ®Ø§Ø° Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37fa3244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a57f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002CC280DE660>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002CC280DF7A0>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model = 'Gemma2-9b-It', groq_api_key= groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0257d0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Ahmed Sharaf, it's nice to meet you! \\n\\nThat's fantastic that you're an AI engineer. It's a really exciting field right now.  \\n\\nIs there anything I can help you with today? Perhaps you'd like to discuss some AI concepts, explore a specific project, or just chat about the latest developments in the field?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 23, 'total_tokens': 102, 'completion_time': 0.143636364, 'prompt_time': 0.002135306, 'queue_time': 0.157774412, 'total_time': 0.14577167}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--d2030072-089f-40b9-bc77-be34f345a767-0', usage_metadata={'input_tokens': 23, 'output_tokens': 79, 'total_tokens': 102})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content = 'Hi, My Name Is Ahmed Sharaf and I am a ai engineer')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5b7fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Ahmed Sharaf and that you are an AI engineer!  \\n\\nIs there anything else you'd like to tell me about yourself or your work? I'm eager to learn more. ğŸ˜Š \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 81, 'total_tokens': 130, 'completion_time': 0.089090909, 'prompt_time': 0.004072432, 'queue_time': 0.16206112900000003, 'total_time': 0.093163341}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--f150d84a-d967-485c-9dbe-b683ba61ee0a-0', usage_metadata={'input_tokens': 81, 'output_tokens': 49, 'total_tokens': 130})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content='Hi, My Name Is Ahmed Sharaf and I am a ai engineer'),\n",
    "        AIMessage(content = \"Hello Ahmed Sharaf, it's nice to meet you! \\n\\nThat's fantastic that you're an AI engineer. It's a really exciting field right now\"), # Ù‡Ù†Ø§ Ø¨Ù‚ÙˆÙ„Ù‡ Ø§Ù† Ø¯Ø§ ÙƒØ§Ù† Ø±Ø¯ Ø§Ù„ Ai \n",
    "        HumanMessage(content = \"Hey What's my name and what do i do ?\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Ù‡Ù†Ø§ Ù‚Ø¯Ø± Ø§Ù†Ù‡ ÙŠÙØªÙƒØ± Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ù‡ Ø¨Ø³ Ø§Ø­Ù†Ø§ Ø§Ø¯ÙŠÙ†Ù‡Ø§Ù„Ù‡ ÙŠØ¯ÙˆÙŠØ§ Ø¨Ù†ÙØ³Ù†Ø§\n",
    "# Ø§Ø²Ø§Ù‰ Ù†Ø¹Ù…Ù„ Ø§Ù„ÙƒÙ„Ø§Ù… Ø¯Ø§ ØªÙ„Ù‚Ø§Ø¦ÙŠ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6003c325",
   "metadata": {},
   "source": [
    "### Message History\n",
    "<div dir='rtl'>\n",
    "Ù†Ø³ØªØ·ÙŠØ¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… **ÙƒÙ„Ø§Ø³ Message History** Ù„ØªØºÙ„ÙŠÙ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ¬Ø¹Ù„Ù‡ **ÙŠØ­ÙØ¸ Ø§Ù„Ø­Ø§Ù„Ø© (stateful)**.  \n",
    "Ù‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù†Ù‡ Ø³ÙŠÙ‚ÙˆÙ… Ø¨ØªØªØ¨Ø¹ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª ÙˆØ§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ ÙˆÙŠØ®Ø²Ù†Ù‡Ø§ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ùˆ Ù…ÙƒØ§Ù† ØªØ®Ø²ÙŠÙ† Ù…Ø¹ÙŠÙ†.\n",
    "datastore\n",
    "ÙˆØ¨Ø§Ù„ØªØ§Ù„ÙŠØŒ Ø¹Ù†Ø¯ Ø§Ù„ØªÙØ§Ø¹Ù„ ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ØŒ ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ù‡Ø°Ù‡ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© ÙˆØªÙ…Ø±ÙŠØ±Ù‡Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ù€ chain ÙƒØ¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ØŒ Ù…Ù…Ø§ ÙŠØ³Ù…Ø­ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨ÙÙ‡Ù… Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©.\n",
    "\n",
    "---\n",
    "\n",
    "Ø¯Ø¹ÙˆÙ†Ø§ Ù†Ø±Ù‰ ÙƒÙŠÙÙŠØ© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ø§ Ø§Ù„Ù…ÙÙ‡ÙˆÙ… Ø¹Ù…Ù„ÙŠÙ‹Ø§!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2181d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# Ø§ÙˆÙ„ Ø­Ø§Ø¬Ù‡ Ø§Ø²Ø§Ù‰ Ù†ÙØ±Ù‚ Ø¨ÙŠÙ† Ø§Ù„Ø³ÙŠØ´Ù†Ø² Ø§Ù„Ù…Ø®ØªÙ„ÙÙ‡ ÙŠØ¹Ù†ÙŠ Ø¨ÙŠÙ† Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙÙ‡\n",
    "# Ø¯Ø§ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø¯Ø§Ù„Ù‡ Ø¨ØªÙˆØ´Ù Ø§Ù„ session id\n",
    "# ChatMessageHistory => Ø¯Ø§ ÙÙŠÙ‡ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ù‡ ÙƒØ§Ù…Ù„Ù‡ Ø¨Ø§Ù„ØªØ§Ø±ÙŠØ®\n",
    "\n",
    "# session_id type => string\n",
    "# -> return type\n",
    "store = dict()\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# Ø¹Ù„Ø´Ø§Ù† Ø§Ø®Ù„ÙŠÙ‡ ÙŠØ´Øº Ø§Ù„Ø¯Ø§Ù„Ù‡ Ø¯ÙŠ Ù ÙƒÙ„ Ù…Ø±Ù‡ Ø¨Ù†ÙƒÙ„Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆÙ†Ø®Ø²Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù‡Ù†Ø§\n",
    "# Ø¨Ù†Ø³ØªØ®Ø¯Ù… RunnableWithMessageHistory\n",
    "# Ø¯Ø§ Ø§Ù„Ù„Ù‰ Ø¨ÙŠÙƒÙˆÙ† Ø§Ù„ pipline\n",
    "\n",
    "work_message_history = RunnableWithMessageHistory(model, get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b85b166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Ahmed! It's great to meet you. \\n\\nBeing an AI engineer is such a cutting-edge field. What areas of AI are you most interested in or working on? I'm always curious to hear about the exciting projects people are involved in. ğŸ˜Š  \\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'configurable': {'session_id':'chat1'}}\n",
    "response = work_message_history.invoke(\n",
    "    [HumanMessage(content='Hi, My Name Is Ahmed Sharaf and I am a ai engineer')],\n",
    "    config = config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Ahmed Sharaf.  ğŸ˜Š \\n\\nI remembered it from our first introduction!  \\n\\n\\n\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 174, 'total_tokens': 198, 'completion_time': 0.043636364, 'prompt_time': 0.007277485, 'queue_time': 0.1595678, 'total_time': 0.050913849}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--cd205b2b-42f2-4d94-bb2e-90e77aa37a7b-0', usage_metadata={'input_tokens': 174, 'output_tokens': 24, 'total_tokens': 198})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_message_history.invoke(\n",
    "    [HumanMessage(content='What is my name?')],\n",
    "    config = config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6adbeea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As a large language model, I have no memory of past conversations or access to personal information. Therefore, I don't know your name.\\n\\nIf you'd like to tell me your name, I'd be happy to know!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 14, 'total_tokens': 66, 'completion_time': 0.094545455, 'prompt_time': 0.001914866, 'queue_time': 0.16107137500000002, 'total_time': 0.096460321}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--74d83f09-0b61-47ad-a72e-b16d05590bda-0', usage_metadata={'input_tokens': 14, 'output_tokens': 52, 'total_tokens': 66})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we change the config (session id) the model can't remeber me\n",
    "config1 = {'configurable': {'session_id': 'chat2'}}\n",
    "work_message_history.invoke(\n",
    "    [HumanMessage(content='What is my name?')],\n",
    "    config = config1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34e2ec6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Ali, it's nice to meet you! ğŸ˜Š\\n\\nIs there anything I can help you with today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 77, 'total_tokens': 103, 'completion_time': 0.047272727, 'prompt_time': 0.003847522, 'queue_time': 0.159495923, 'total_time': 0.051120249}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--4c7165a5-62d9-4350-954a-ed857571f832-0', usage_metadata={'input_tokens': 77, 'output_tokens': 26, 'total_tokens': 103})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_message_history.invoke(\n",
    "    [HumanMessage(content='My Name Ali')],\n",
    "    config = config1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47bc362e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Ali.  \\n\\nI remember that you told me earlier!  ğŸ˜„  How can I help you today?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 115, 'total_tokens': 143, 'completion_time': 0.050909091, 'prompt_time': 0.005832969, 'queue_time': 0.160230962, 'total_time': 0.05674206}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--7d8aea32-c238-4658-8edf-442bdc6437c2-0', usage_metadata={'input_tokens': 115, 'output_tokens': 28, 'total_tokens': 143})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_message_history.invoke(\n",
    "    [HumanMessage(content='whats my name?')],\n",
    "    config = config1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26efe1c9",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "# âœ… Ù…Ù„Ø®Øµ ÙˆØ¸Ø§Ø¦Ù:\n",
    "| Ø§Ù„ÙƒÙ„Ø§Ø³ | ÙˆØ¸ÙŠÙØªÙ‡ | Ø¹Ù„Ø§Ù‚ØªÙ‡ Ø¨Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Memory) |\n",
    "|---------|---------|-------------------------|\n",
    "| **ChatMessageHistory** | ÙƒÙ„Ø§Ø³ Ù…Ø³Ø¤ÙˆÙ„ Ø¹Ù† ØªØ®Ø²ÙŠÙ† ÙˆØ§Ø³ØªØ±Ø¬Ø§Ø¹ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ (User + AI) Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© | Ø¨ÙŠØ­ØªÙØ¸ Ø¨Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© (in-memory) Ø£Ùˆ Ù…Ù…ÙƒÙ† ÙŠØªØ®Ø²Ù† ÙÙŠ Ù‚ÙˆØ§Ø¹Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø²ÙŠ Redis |\n",
    "| **BaseChatMessageHistory** | ÙƒÙ„Ø§Ø³ Ù…Ø¬Ø±Ø¯ (Abstract Base Class) Ø¨ÙŠØ­Ø¯Ø¯ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ø£ÙŠ Message History | Ù…Ø´ Ø¨ÙŠØ®Ø²Ù† Ø­Ø§Ø¬Ø© Ø¨Ù†ÙØ³Ù‡ØŒ Ù„ÙƒÙ† Ø¨ÙŠØ­Ø¯Ø¯ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ (interface) Ø§Ù„Ù„ÙŠ ChatMessageHistory ÙˆØºÙŠØ±Ù‡ Ù„Ø§Ø²Ù… ÙŠÙ„ØªØ²Ù…ÙˆØ§ Ø¨ÙŠÙ‡Ø§ |\n",
    "| **RunnableWithMessageHistory** | Wrapper Ø¨ÙŠØ±Ø¨Ø· Ø§Ù„Ù€ Chain Ø£Ùˆ Runnable Ø¨ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠ | Ø¨ÙŠØ§Ø®Ø¯ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ù…Ù† Ø§Ù„Ù€ historyØŒ ÙŠÙ…Ø±Ø±Ù‡Ø§ Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ØŒ ÙˆØ¨Ø¹Ø¯ Ø§Ù„Ø±Ø¯ Ø¨ÙŠØ­Ø¯Ø« Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¨Ø¯ÙˆÙ† Ù…Ø§ Ø§Ù†Øª ØªØªØ¯Ø®Ù„ |\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Ø¨Ø§Ø®ØªØµØ§Ø±:\n",
    "- **ChatMessageHistory** = Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„ÙØ¹Ù„ÙŠ Ù„Ù„Ø±Ø³Ø§Ø¦Ù„ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©.\n",
    "- **BaseChatMessageHistory** = Ø§Ù„Ù‚Ø§Ù„Ø¨ Ø§Ù„Ù„ÙŠ ÙƒÙ„ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù€ history Ù„Ø§Ø²Ù… ØªÙ…Ø´ÙŠ Ø¹Ù„ÙŠÙ‡.\n",
    "- **RunnableWithMessageHistory** = Ø§Ù„ÙƒØ§Ø¦Ù† Ø§Ù„Ù„ÙŠ Ø¨ÙŠØ±Ø¨Ø· Ø§Ù„Ù€ Chain Ù…Ø¹ Ø§Ù„ØªØ§Ø±ÙŠØ® ØªÙ„Ù‚Ø§Ø¦ÙŠ ÙˆÙŠØ®Ù„ÙŠÙƒ ØªÙ†Ø³Ù‰ Ø§Ù„ØªÙØ§ØµÙŠÙ„.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf7a7c2",
   "metadata": {},
   "source": [
    "### Prompt templates\n",
    "Prompt Templates help to turn raw user information into a format that the LLM can work with. In this case, the raw user input is just a message, which we are passing to the LLM. Let's now make that a bit more complicated. First, let's add in a system message with some custom instructions (but still taking messages as input). Next, we'll add in more input besides just the messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1ee93f",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "# âœ… Ù…Ø§ Ù‡Ùˆ MessagesPlaceholder ÙÙŠ LangChainØŸ\n",
    "\n",
    "### ğŸŸ¡ Ø§Ù„ØªØ¹Ø±ÙŠÙ:\n",
    "- `MessagesPlaceholder` Ù‡Ùˆ **Ù…ÙƒÙˆÙ† (Component)** Ø¨ÙŠÙ…Ø«Ù„ **Ù…ÙƒØ§Ù† Ù…Ø®ØµØµ** Ø¯Ø§Ø®Ù„ Ø§Ù„Ù€ Prompt Template.\n",
    "- ÙˆØ¸ÙŠÙØªÙ‡ Ø¥Ù†Ù‡ ÙŠÙƒÙˆÙ† Ù…ÙƒØ§Ù† (Placeholder) Ù†Ù‚Ø¯Ø± Ù†Ø­Ø· ÙÙŠÙ‡ ** Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ (Message)** Ø¨Ø¹Ø¯ÙŠÙ†.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Ù„ÙŠÙ‡ Ø¨Ù†Ø³ØªØ®Ø¯Ù…Ù‡ØŸ\n",
    "| Ø§Ù„Ø³Ø¨Ø¨ | Ø§Ù„Ø´Ø±Ø­ |\n",
    "|--------|-------|\n",
    "| **Ø¹Ø´Ø§Ù† Ù†Ø¯Ø®Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ® ÙÙŠ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¨Ø³Ù‡ÙˆÙ„Ø©** | Ø¨Ø¯Ù„ Ù…Ø§ Ù†ÙƒØªØ¨ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ ÙŠØ¯ÙˆÙŠ Ø¬ÙˆØ§ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨ØªØŒ Ø¨Ù†Ø­Ø· MessagesPlaceholder ÙˆÙ‡Ùˆ Ø¨ÙŠØ³ØªÙ‚Ø¨Ù„Ù‡Ø§ ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ°. |\n",
    "| **ÙŠØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ ØªØ±ØªÙŠØ¨ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ (User + AI)** | Ø¨ÙŠØ¶ÙŠÙ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„ØµØ­ ÙÙŠ Ø§Ù„Ù€ input Ø¨ØªØ§Ø¹ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„. |\n",
    "| **Ø¨ÙŠØ´ØªØºÙ„ Ù…Ø¹ RunnableWithMessageHistory** | Ù„Ù…Ø§ ØªØ³ØªØ®Ø¯Ù…Ù‡Ù… Ù…Ø¹ Ø¨Ø¹Ø¶ØŒ Ø§Ù„Ù€ Placeholder Ø¯Ù‡ Ø¨ÙŠØªÙ…Ù„Ù‘Ù‰ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¨Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ù„ÙŠ Ù…Ø­ÙÙˆØ¸. |\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98360a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', 'You Are a helpful assistant. Answer all the question to the nest of your ability'),\n",
    "        MessagesPlaceholder(variable_name = 'messages')\n",
    "    ]\n",
    ")\n",
    "chain = prompt|model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a885631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Ahmed Sharaf, it's nice to meet you!\\n\\nI'm ready to answer your questions to the best of my ability.  What can I help you with today? ğŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 32, 'total_tokens': 76, 'completion_time': 0.08, 'prompt_time': 0.002365776, 'queue_time': 0.16124811700000002, 'total_time': 0.082365776}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--cca7a0b7-aaeb-40da-9f90-c99cf10af8f7-0', usage_metadata={'input_tokens': 32, 'output_tokens': 44, 'total_tokens': 76})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'messages':[HumanMessage(content = 'Hi My Name Is Ahmed Sharaf')]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bda7176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How Invoke with messages history\n",
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3da6ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config3 = {'configurable': {'session_id': \"chat4\"}}\n",
    "respone = with_message_history.invoke(\n",
    "    [HumanMessage(content = 'Hi My Name Is Ahmed Sharaf')],\n",
    "    config=config3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fed3742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Ahmed Sharaf, it's nice to meet you! \\n\\nI'm happy to help with any questions you have.  \\n\\nWhat can I do for you today? ğŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 32, 'total_tokens': 75, 'completion_time': 0.078181818, 'prompt_time': 0.002337925, 'queue_time': 0.161324813, 'total_time': 0.080519743}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--ff84c9a8-ca5e-4aae-812c-d7408f174e19-0', usage_metadata={'input_tokens': 32, 'output_tokens': 43, 'total_tokens': 75})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0189dc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Ahmed! It's great to meet you. \\n\\nBeing an AI engineer is such a cutting-edge field. What areas of AI are you most interested in or working on? I'm always curious to hear about the exciting projects people are involved in. ğŸ˜Š  \\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respone = with_message_history.invoke(\n",
    "    [HumanMessage(content = \"what's my name?\")],\n",
    "    config=config3\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ddb5e973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets add multiple variable\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', 'You are a helpful assistant. Answer all Question to the best of your ability in {language}'),\n",
    "        MessagesPlaceholder(variable_name='messages')\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1da33617",
   "metadata": {},
   "outputs": [],
   "source": [
    "respone = chain.invoke({'messages': [HumanMessage(content=\"Hi my name is ahmed\")], 'language': 'arabic'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1d941840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø£Ø­Ù…Ø¯ØŒ ÙŠØ³Ø¹Ø¯Ù†ÙŠ Ø§Ù„ØªØ¹Ø±Ù‘Ù Ø¹Ù„ÙŠÙƒ! \\n\\nÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ  ğŸ˜Š \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 32, 'total_tokens': 62, 'completion_time': 0.054545455, 'prompt_time': 0.002398085, 'queue_time': 0.161231276, 'total_time': 0.05694354}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--aadfd6c3-6f9b-4fa6-abce-5df44468f1c4-0', usage_metadata={'input_tokens': 32, 'output_tokens': 30, 'total_tokens': 62})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a155b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, \n",
    "                                                  get_session_history,\n",
    "                                                  input_messages_key='messages')\n",
    "\n",
    "# input_messages_key => Ù‡Ù†Ø§ Ø¨ØªØ¹Ø±ÙÙ‡ Ø¹Ù„Ù‰ Ø§Ù„ messages Ø§Ù„Ù„Ù‰ Ù‡ØªØ¯Ø®Ù„Ù‡ \n",
    "# Ù„Ø§Ø­Ø¸ Ø§Ù‰ Ù…ØªØ¹ÙŠØ± Ù Ø§Ù„ prompt Ø¨Ù†Ø¯Ø®Ù„ Ù‚ÙŠÙ…ØªÙ‡ Ù‡Ù†Ø§ Ø¨ dictionary \n",
    "# key => Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ± Ù Ø§Ù„ prompt\n",
    "# value => Ø§Ù„Ù‚ÙŠÙ…Ù‡ Ø§Ù„Ù„Ù‰ Ù‡ÙŠØ¹ÙˆØ¶ Ø¨ÙŠÙ‡Ø§ Ù…ÙƒØ§Ù†Ù‡ Ù Ø§Ù„ prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbf6017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ù…Ø±Ø­Ø¨Ø§ Ø£Ø­Ù…Ø¯ØŒ ÙŠØ³Ø¹Ø¯Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ!  \\n\\n(Hello Ahmed, I'm happy to help you! )\\n\\nÙ…Ø§ Ø§Ù„Ø°ÙŠ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø£Ù† Ø£ÙØ¹Ù„ Ù„ÙƒØŸ \\n\\n(What can I do for you?) \\n\\n\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_5 = {'configurable': {'session_id': 'chat10'}}\n",
    "response = with_message_history.invoke(\n",
    "    {'messages': [HumanMessage(content='Hi, I am ahmed')],\n",
    "     'language': 'Arabic'},\n",
    "    config=config_5\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c713220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ø§Ø³Ù…Ùƒ Ø£Ø­Ù…Ø¯. ğŸ˜Š \\n\\n(Your name is Ahmed. ğŸ˜Š) \\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {'messages': [HumanMessage(content='what is my name?')],\n",
    "     'language': 'Arabic'},\n",
    "    config=config_5\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ff4d0f",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "# âœ… Ø¥Ø¯Ø§Ø±Ø© ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (Managing Conversation History)\n",
    "\n",
    "### ğŸŸ¡ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:\n",
    "- ÙƒÙ„ Ù…Ø±Ø© Ø¨Ù†ØªÙƒÙ„Ù… Ù…Ø¹ Ø§Ù„Ø´Ø§Øª Ø¨ÙˆØªØŒ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ (user + AI) Ø¨ØªØ¶Ø§Ù Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©.\n",
    "- Ù…Ø¹ Ø§Ù„ÙˆÙ‚ØªØŒ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¨ÙŠÙƒØ¨Ø± Ø¬Ø¯Ù‹Ø§ ÙˆÙ…Ù…ÙƒÙ†:\n",
    "  - **ÙŠØªØ¬Ø§ÙˆØ² Ø§Ù„Ù€ Context Window** Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ (ÙŠØ¹Ù†ÙŠ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ø´ Ù‡ÙŠÙ‚Ø¯Ø± ÙŠØ´ÙˆÙ ÙƒÙ„ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„).\n",
    "  - ÙŠØ¨Ø·Ù‘Ø£ Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆÙŠØ³ØªÙ‡Ù„Ùƒ Tokens Ø²ÙŠØ§Ø¯Ø©.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Ø§Ù„Ø­Ù„: Ø§Ø³ØªØ®Ø¯Ø§Ù… **Trimmer**\n",
    "- Ù‡Ùˆ Ø£Ø¯Ø§Ø© (Helper Function) Ø¨ØªØ³Ø§Ø¹Ø¯ ÙÙŠ **ØªÙ‚Ù„ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„Ø±Ø³Ø§Ø¦Ù„** Ø§Ù„Ù„ÙŠ Ø¨Ù†Ø¨Ø¹ØªÙ‡Ø§ Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„.\n",
    "- Ø§Ù„Ù‡Ø¯Ù Ø¥Ù†Ù†Ø§ Ù†ÙØ¶Ù„ Ù…Ø­Ø§ÙØ¸ÙŠÙ† Ø¹Ù„Ù‰ **Ø£Ù‡Ù… Ø§Ù„Ø±Ø³Ø§Ø¦Ù„** Ø¨Ø³ØŒ ÙˆØ§Ù„Ø¨Ø§Ù‚ÙŠ Ø¨Ù†Ø±Ù…ÙŠÙ‡ Ø£Ùˆ Ø¨Ù†Ù‚ØµÙ‡.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… ÙˆØ¸ÙŠÙØ© `trim_messages`:\n",
    "| Ø§Ù„Ø®Ø§ØµÙŠØ© | Ø´Ø±Ø­Ù‡Ø§ |\n",
    "|----------|-------|\n",
    "| **ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ù€ Tokens Ø§Ù„Ù„ÙŠ Ø¹Ø§ÙŠØ²ÙŠÙ† Ù†Ø­Ø§ÙØ¸ Ø¹Ù„ÙŠÙ‡Ù…** | Ø¨Ù†Ù‚ÙˆÙ„ Ù„Ù‡ Ù…Ø«Ù„Ù‹Ø§: \"Ù…Ø§ ØªØªØ¹Ø¯Ø§Ø´ 2000 token\" |\n",
    "| **Ø¥Ø¨Ù‚Ø§Ø¡ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù€ System Ø¯Ø§ÙŠÙ…Ù‹Ø§** | Ø¹Ø´Ø§Ù† ØªÙˆØ¬Ù‡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¯Ø§ÙŠÙ…Ù‹Ø§ Ù…Ù‡Ù…Ø§ Ù‚ØµÙŠÙ†Ø§ Ù…Ù† Ø§Ù„ØªØ§Ø±ÙŠØ®. |\n",
    "| **Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„Ù€ Partial Messages** | ÙŠØ¹Ù†ÙŠ Ù…Ù…ÙƒÙ† Ù†Ù‚Øµ Ø¬Ø²Ø¡ Ù…Ù† Ø±Ø³Ø§Ù„Ø© Ø¨Ø¯Ù„ Ù…Ø§ Ù†Ù…Ø³Ø­Ù‡Ø§ ÙƒÙ„Ù‡Ø§. |\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Ù„ÙŠÙ‡ Ù…Ù‡Ù…ØŸ\n",
    "- Ø¨ÙŠØ­Ù…ÙŠÙƒ Ù…Ù† **Overflow** ÙÙŠ Ø§Ù„Ù€ Context.\n",
    "- Ø¨ÙŠØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ **Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø£Ù‡Ù…** (recent messages + system prompt).\n",
    "- Ø¨ÙŠØ®Ù„ÙŠ Ø§Ù„Ø´Ø§Øª Ø¨ÙˆØª **Ø´ØºØ§Ù„ Ø¨ÙƒÙØ§Ø¡Ø©** Ø­ØªÙ‰ Ù…Ø¹ Ø¬Ù„Ø³Ø§Øª Ø·ÙˆÙŠÙ„Ø©.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a46f55ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens = 45,\n",
    "    strategy = 'last', # Ø§Ù„Ø·Ø±ÙŠÙ‚Ù‡ Ø§Ù„Ù„Ù‰ Ù‡ÙŠØ¹Ø±Ù Ø¨ÙŠÙ‡Ø§ Ø§Ù† Ø¯ÙŠ Ø§Ù‡Ù… Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ ÙÙŠØ­Ø§ÙØ¸ Ø¹Ù„ÙŠÙ‡ ÙˆÙŠØ±Ù…ÙŠ Ø§Ù„Ø¨Ø§Ù‚ÙŠ\n",
    "    token_counter = model,\n",
    "    include_system = True,\n",
    "    allow_partial = False,\n",
    "    start_on = 'human'\n",
    ")\n",
    "\n",
    "# Ø¨Ù†ÙŠÙ†Ø§ Ù…Ø­Ø§Ø¯Ø«Ù‡ Ø¨ÙŠÙ† Ø§Ù†Ø³Ø§Ù† ÙˆØ°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹Ù‰\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d3f307",
   "metadata": {},
   "source": [
    "## âœ… Trimmer Parameters\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "\n",
    "| Ø§Ù„Ø¨Ø±Ø§Ù…ÙŠØªØ±               | Ø§Ù„ÙˆØ¸ÙŠÙØ©                                    | Ø§Ù„ØªÙØ³ÙŠØ±                                                   |\n",
    "|------------------------|--------------------------------------------|-----------------------------------------------------------|\n",
    "| `max_tokens = 45`       | Ø£Ù‚ØµÙ‰ Ø¹Ø¯Ø¯ Ù…Ù† Ø§Ù„Ù€ Tokens Ø¨Ø¹Ø¯ Ø§Ù„ØªØ±ÙŠÙ…Ù†Ø¬        | Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù‡ÙŠØ´ÙˆÙ Ø±Ø³Ø§Ø¦Ù„ Ù…Ø¬Ù…ÙˆØ¹Ù‡Ù… Ù„Ø§ ÙŠØªØ¬Ø§ÙˆØ² 45 Token ÙÙ‚Ø·         |\n",
    "| `strategy = 'last'`     | Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø±Ø³Ø§Ø¦Ù„                 | Ù‡ÙŠØ­ØªÙØ¸ Ø¨Ø¢Ø®Ø± Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ (Ø§Ù„Ø£Ø­Ø¯Ø«) ÙˆÙŠÙ‚Øµ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©                  |\n",
    "| `token_counter = model` | Ø£Ø¯Ø§Ø© Ù„Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ù€ Tokens ÙÙŠ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„       | Ø¨ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù†ÙØ³Ù‡ Ù„Ø­Ø³Ø§Ø¨ Ø­Ø¬Ù… Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø¨Ø§Ù„ØªÙˆÙƒÙ†Ø²           |\n",
    "| `include_system = True` | Ù‡Ù„ Ù†Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ system message Ù…Ù‡Ù…Ø§ Ø­ØµÙ„ØŸ     | Ù†Ø¹Ù…ØŒ Ù‡ØªÙØ¶Ù„ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù€ system Ù…ÙˆØ¬ÙˆØ¯Ø© Ø­ØªÙ‰ Ø¨Ø¹Ø¯ Ø§Ù„Ù‚Øµ           |\n",
    "| `allow_partial = False` | Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ù‚Øµ Ø¬Ø²Ø¡ Ù…Ù† Ø±Ø³Ø§Ù„Ø©ØŸ                  | Ù„Ø£ØŒ Ø¥Ù…Ø§ Ø§Ù„Ø±Ø³Ø§Ù„Ø© ØªÙØ¶Ù„ ÙƒØ§Ù…Ù„Ø© Ø£Ùˆ ØªØªØ´Ø§Ù„ Ø®Ø§Ù„Øµ                   |\n",
    "| `start_on = 'human'`    | Ù…Ù†ÙŠÙ† Ù†Ø¨Ø¯Ø£ Ø§Ù„ØªØ±ÙŠÙ…Ù†Ø¬ØŸ                       | Ù‡ÙŠØ¨Ø¯Ø£ Ù…Ù† Ø£ÙˆÙ„ Ø±Ø³Ø§Ù„Ø© Ø¨Ø´Ø±ÙŠØ© (Human Message)                   |\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "16cb99a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯ Ø§ÙØªØ±Ø§Ø¶ÙŠ ÙˆÙ„Ø§ Ø£Ø¹Ø±Ù ØªÙØ¶ÙŠÙ„Ø§ØªÙƒ Ø§Ù„Ø´Ø®ØµÙŠØ©ØŒ Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ Ù†ÙˆØ¹ Ø§Ù„Ø¢ÙŠØ³ ÙƒØ±ÙŠÙ… Ø§Ù„Ø°ÙŠ ØªØ­Ø¨Ù‡.  \\n\\nÙ‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø´Ø§Ø±ÙƒØ© Ù†ÙˆØ¹ Ø§Ù„Ø¢ÙŠØ³ ÙƒØ±ÙŠÙ… Ø§Ù„Ø°ÙŠ ØªÙØ¶Ù„Ù‡ØŸ ğŸ˜Š \\n\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how do pass trimmer in chain ?\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter('messages')|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "response = chain.invoke(\n",
    "    {\n",
    "    'messages': messages + [HumanMessage(content = 'What ice cream do i like')],\n",
    "    'language': 'Arabic'\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3895f4eb",
   "metadata": {},
   "source": [
    "-  Ù‡Ù†Ø§ Ù…ÙØªÙƒØ±Ø´ Ø¹Ù„Ø´Ø§Ù† Ø§Ù„ trimmer Ù…Ø®Ø¯Ø´ Ø§Ù„Ø¬Ø²Ø¡ Ø¯Ø§ Ù Ø§Ù„Ù…Ù‡Ù… Ø§Ù„Ù„Ù‰ Ø¨Ø¹ØªÙ‡ Ù„Ù‡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d33a4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ø³Ø£Ù„ØªÙ†ÙŠ 2 + 2  \\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "    'messages': messages + [HumanMessage(content = 'What math problem did i ask')],\n",
    "    'language': 'Arabic'\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bfe22843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have memory of past conversations or personal information about you.  So I don't know your name. Would you like to tell me? ğŸ˜Š  \\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets Wrap this in the Message History\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key='messages'\n",
    ")\n",
    "config = {'configurable': {'session_id': 'chat100'}}\n",
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        'messages': messages + [HumanMessage(content = \"what's my name\")],\n",
    "        'language': 'English'\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf90f58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
